{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from setup import setup\n",
    "setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 1281167\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 100000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "imagenet = datasets.load_dataset(\"ILSVRC/imagenet-1k\", trust_remote_code=True)\n",
    "print(imagenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.supcl.util import TwoCropTransform\n",
    "from torchvision import transforms\n",
    "\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "normalize = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomResizedCrop(size=32, scale=(0.2, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': [tensor([[[ 0.2282,  0.2796,  0.3138,  ...,  0.5193,  0.5364,  0.5707],\n",
       "           [ 0.2796,  0.3309,  0.3138,  ...,  0.6392,  0.6563,  0.6049],\n",
       "           [ 0.3481,  0.3481,  0.3481,  ...,  0.7419,  0.7077,  0.1939],\n",
       "           ...,\n",
       "           [ 0.9132,  0.9132,  0.9132,  ...,  0.9132,  0.9303,  0.9303],\n",
       "           [ 0.9303,  0.9303,  0.9303,  ...,  0.8961,  0.8789,  0.8961],\n",
       "           [ 0.9303,  0.9474,  0.9474,  ...,  0.9132,  0.9132,  0.9132]],\n",
       "  \n",
       "          [[ 0.4328,  0.4678,  0.4678,  ...,  0.7304,  0.7304,  0.7304],\n",
       "           [ 0.4678,  0.4853,  0.5028,  ...,  0.8354,  0.8529,  0.7304],\n",
       "           [ 0.5028,  0.5028,  0.5028,  ...,  0.9230,  0.8354, -0.0574],\n",
       "           ...,\n",
       "           [ 1.0630,  1.0630,  1.0630,  ...,  1.0280,  1.0280,  1.0280],\n",
       "           [ 1.0455,  1.0455,  1.0630,  ...,  1.0105,  0.9755,  0.9930],\n",
       "           [ 1.0455,  1.0455,  1.0805,  ...,  1.0455,  1.0455,  1.0630]],\n",
       "  \n",
       "          [[ 0.6879,  0.7054,  0.7054,  ...,  0.8622,  0.8448,  0.8274],\n",
       "           [ 0.7054,  0.7228,  0.7228,  ...,  0.9842,  0.9842,  0.8448],\n",
       "           [ 0.7576,  0.7925,  0.7925,  ...,  1.1062,  0.9668,  0.0431],\n",
       "           ...,\n",
       "           [ 1.2805,  1.2805,  1.2631,  ...,  1.1585,  1.1759,  1.1759],\n",
       "           [ 1.3154,  1.3154,  1.2805,  ...,  1.1411,  1.1237,  1.1411],\n",
       "           [ 1.3154,  1.3154,  1.2980,  ...,  1.1759,  1.1759,  1.1934]]]),\n",
       "  tensor([[[0.3994, 0.3823, 0.3994,  ..., 0.5707, 0.5707, 0.5707],\n",
       "           [0.4166, 0.4337, 0.4508,  ..., 0.6392, 0.6392, 0.6734],\n",
       "           [0.4508, 0.4679, 0.4851,  ..., 0.8276, 0.8447, 0.8789],\n",
       "           ...,\n",
       "           [1.1872, 1.1529, 0.8789,  ..., 1.1529, 1.1700, 1.1700],\n",
       "           [1.2214, 1.2043, 1.1529,  ..., 1.2043, 1.2043, 1.1872],\n",
       "           [1.2385, 1.2214, 1.1872,  ..., 1.2043, 1.2043, 1.2043]],\n",
       "  \n",
       "          [[0.5378, 0.5378, 0.5553,  ..., 0.7479, 0.7479, 0.7479],\n",
       "           [0.5728, 0.5728, 0.5903,  ..., 0.8179, 0.8179, 0.8529],\n",
       "           [0.6078, 0.6078, 0.6254,  ..., 1.0105, 1.0280, 1.0630],\n",
       "           ...,\n",
       "           [1.3431, 1.3081, 1.0630,  ..., 1.2906, 1.3081, 1.3081],\n",
       "           [1.3431, 1.3431, 1.3081,  ..., 1.3431, 1.3606, 1.3256],\n",
       "           [1.3606, 1.3606, 1.3431,  ..., 1.3606, 1.3431, 1.3256]],\n",
       "  \n",
       "          [[0.7925, 0.8274, 0.8274,  ..., 0.9494, 0.9494, 0.9494],\n",
       "           [0.8274, 0.8448, 0.8622,  ..., 1.0017, 1.0017, 1.0365],\n",
       "           [0.8797, 0.8971, 0.8971,  ..., 1.1759, 1.2108, 1.2282],\n",
       "           ...,\n",
       "           [1.5420, 1.5071, 1.2282,  ..., 1.4200, 1.4200, 1.4200],\n",
       "           [1.5768, 1.5594, 1.5071,  ..., 1.4897, 1.4897, 1.4548],\n",
       "           [1.6117, 1.6117, 1.5594,  ..., 1.4897, 1.4897, 1.4374]]])],\n",
       " 'label': 726}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.supcl.util import load_imagenet_hf\n",
    "imagenet_train = load_imagenet_hf(object(), TwoCropTransform(train_transform))['train']\n",
    "imagenet_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'label'],\n",
       "    num_rows: 1281167\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets as torchvision_datasets\n",
    "from src.supcl.util import TwoCropTransform\n",
    "cifar10_dataset = torchvision_datasets.CIFAR10(\n",
    "    root='../datasets/', transform=TwoCropTransform(train_transform), download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([[[-1.0219, -1.1589, -1.1418,  ..., -0.1143, -0.1143, -0.0972],\n",
       "           [-1.3987, -1.5699, -1.4672,  ..., -0.3712, -0.3883, -0.4568],\n",
       "           [-1.3815, -1.5014, -1.2959,  ..., -0.3198, -0.4226, -0.5253],\n",
       "           ...,\n",
       "           [ 0.3652,  0.0912, -0.0801,  ..., -0.2513,  0.2624,  0.2453],\n",
       "           [ 0.3823,  0.1426, -0.0116,  ..., -0.5253,  0.0741, -0.0287],\n",
       "           [ 0.2967,  0.1254,  0.0741,  ..., -1.0904, -0.3369, -0.1486]],\n",
       "  \n",
       "          [[-0.9153, -1.0553, -1.0378,  ...,  0.0126,  0.0126,  0.0301],\n",
       "           [-1.3004, -1.4755, -1.3704,  ..., -0.2500, -0.2675, -0.3375],\n",
       "           [-1.2829, -1.4055, -1.1954,  ..., -0.1975, -0.3025, -0.4076],\n",
       "           ...,\n",
       "           [ 0.5028,  0.2227,  0.0476,  ..., -0.1275,  0.3978,  0.3803],\n",
       "           [ 0.5203,  0.2752,  0.1176,  ..., -0.4076,  0.2052,  0.1001],\n",
       "           [ 0.4328,  0.2577,  0.2052,  ..., -0.9853, -0.2150, -0.0224]],\n",
       "  \n",
       "          [[-0.6890, -0.8284, -0.8110,  ...,  0.2348,  0.2348,  0.2522],\n",
       "           [-1.0724, -1.2467, -1.1421,  ..., -0.0267, -0.0441, -0.1138],\n",
       "           [-1.0550, -1.1770, -0.9678,  ...,  0.0256, -0.0790, -0.1835],\n",
       "           ...,\n",
       "           [ 0.7228,  0.4439,  0.2696,  ...,  0.0953,  0.6182,  0.6008],\n",
       "           [ 0.7402,  0.4962,  0.3393,  ..., -0.1835,  0.4265,  0.3219],\n",
       "           [ 0.6531,  0.4788,  0.4265,  ..., -0.7587,  0.0082,  0.1999]]]),\n",
       "  tensor([[[-0.4739, -0.4226, -0.4397,  ..., -1.0733, -1.2959, -1.2959],\n",
       "           [-0.4568, -0.4226, -0.4568,  ..., -0.8507, -0.9705, -1.0733],\n",
       "           [-0.4054, -0.4054, -0.4568,  ..., -0.6965, -0.6452, -0.8164],\n",
       "           ...,\n",
       "           [-0.0629, -0.2342, -0.3712,  ..., -0.0116, -0.8507, -1.1075],\n",
       "           [ 0.1083, -0.0116, -0.1657,  ..., -0.2342, -1.1247, -1.2103],\n",
       "           [ 0.2282,  0.1426,  0.0398,  ..., -0.2856, -1.1075, -1.0904]],\n",
       "  \n",
       "          [[-0.3550, -0.3025, -0.3200,  ..., -0.9678, -1.1954, -1.1954],\n",
       "           [-0.3375, -0.3025, -0.3375,  ..., -0.7402, -0.8627, -0.9678],\n",
       "           [-0.2850, -0.2850, -0.3375,  ..., -0.5826, -0.5301, -0.7052],\n",
       "           ...,\n",
       "           [ 0.0651, -0.1099, -0.2500,  ...,  0.1176, -0.7402, -1.0028],\n",
       "           [ 0.2402,  0.1176, -0.0399,  ..., -0.1099, -1.0203, -1.1078],\n",
       "           [ 0.3627,  0.2752,  0.1702,  ..., -0.1625, -1.0028, -0.9853]],\n",
       "  \n",
       "          [[-0.1312, -0.0790, -0.0964,  ..., -0.7413, -0.9678, -0.9678],\n",
       "           [-0.1138, -0.0790, -0.1138,  ..., -0.5147, -0.6367, -0.7413],\n",
       "           [-0.0615, -0.0615, -0.1138,  ..., -0.3578, -0.3055, -0.4798],\n",
       "           ...,\n",
       "           [ 0.2871,  0.1128, -0.0267,  ...,  0.3393, -0.5147, -0.7761],\n",
       "           [ 0.4614,  0.3393,  0.1825,  ...,  0.1128, -0.7936, -0.8807],\n",
       "           [ 0.5834,  0.4962,  0.3916,  ...,  0.0605, -0.7761, -0.7587]]])],\n",
       " 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10_dataset[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
