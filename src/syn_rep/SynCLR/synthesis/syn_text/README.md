In order to generate captions for other concepts or backgrounds of your own interest, we put the caption synthesizing code in the `syn_text` folder.
Please refer to Meta [LLaMA 2 page](https://github.com/facebookresearch/llama/tree/llama_v2) for instructions on model access and environment setup. 
The synthesized text could be generated by running the following command:
```
export LLAMA_FOLDER=/PATH/TO/LLAMA/WEIGHTS
export PYTHONPATH=/PATH/TO/LLAMA/

torchrun --nproc_per_node 1 --master_port 12388 \
    synthesize_text.py --ckpt_dir ${LLAMA_FOLDER}/llama-2-7b --tokenizer_path ${LLAMA_FOLDER}/tokenizer.model \
    --max_batch_size 5 --max_seq_len 400 --max_gen_len 100 \
    --total_captions 100 --seed 0 --output_filename synthetic_caption.txt --temperature 0.8 
```
#### Main Arguments
- `--total_captions`: number of captions to generate
- `--seed`: random seed for synthesizing captions 
- `--output_filename`: output path
- `--temperature`: higher temperature results in more diverse text
  
